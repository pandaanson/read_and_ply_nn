{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qunatiles: [0.5 0.6 0.4 0.7 0.3 0.8 0.2 0.9 0.1]\n",
      "Manual Outputs: [2426901354.444373, 2480358491.406657, 2307159306.8403263, 2601671413.990361, 2210020239.564946, 2872144448.735074, 2178552543.5306993, 7136673349.902651, 2097353085.123003]\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Self\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "class QuantileModelPredictor:\n",
    "    def __init__(self, model_directory):\n",
    "        # Load the scaler and ensure it outputs float64\n",
    "        self.scaler = joblib.load(os.path.join(model_directory, 'scaler.pkl'))\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Load quantiles and their corresponding model weights and biases\n",
    "        quantiles = np.load(os.path.join(model_directory, 'quantiles.npy'), allow_pickle=True)\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "        for q in self.quantiles:\n",
    "            model_path = os.path.join(model_directory, f'model_quantile_{q:.2f}.pth')\n",
    "            model_info = torch.load(model_path)\n",
    "            # Initialize lists to hold weights and biases for the quantile model\n",
    "            model_weights = []\n",
    "            model_biases = []\n",
    "\n",
    "            # Extract weights and biases from model state dictionary and convert them to float64\n",
    "            for name, param in model_info['state_dict'].items():\n",
    "                if 'weight' in name:\n",
    "                    model_weights.append(param.detach().numpy().astype(np.float64))\n",
    "                elif 'bias' in name:\n",
    "                    model_biases.append(param.detach().numpy().astype(np.float64))\n",
    "\n",
    "            self.weights.append(model_weights)\n",
    "            self.biases.append(model_biases)\n",
    "\n",
    "\n",
    "    def predict_quantiles(self, inputs):\n",
    "      inputs = np.array(inputs, dtype=np.float64).reshape(1, -1)\n",
    "      scaled_inputs = self.scaler.transform(inputs).astype(np.float64)\n",
    "\n",
    "      manual_outputs = []\n",
    "      for i in range(len(self.quantiles)):\n",
    "          x = scaled_inputs\n",
    "          layers = len(self.weights[i])\n",
    "          for j in range(layers):\n",
    "              weights = self.weights[i][j]\n",
    "              biases = self.biases[i][j]\n",
    "              x = np.dot(x, weights.T) + biases\n",
    "              if j < layers - 1:  # Apply ReLU to all but the last layer\n",
    "                  x = np.maximum(0, x)\n",
    "          manual_outputs.append(x.flatten()[0])\n",
    "\n",
    "      return manual_outputs\n",
    "\n",
    "# Usage example:\n",
    "model_directory = '/home/yui/Downloads/read_and_play/model_output'  # Adjust the path as necessary\n",
    "predictor = QuantileModelPredictor(model_directory)\n",
    "inputs = [5000, 1000, 15000, 2000,5]  # Example inputs\n",
    "manual_outputs = predictor.predict_quantiles(inputs)\n",
    "print(\"qunatiles:\", predictor.quantiles)\n",
    "print(\"Manual Outputs:\", manual_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gurobipy in /home/yui/.local/lib/python3.10/site-packages (11.0.2)\n",
      "Gurobi Optimizer version 11.0.2 build v11.0.2rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1 rows, 5 columns and 5 nonzeros\n",
      "Model fingerprint: 0x0f216fb8\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [1e+04, 1e+04]\n",
      "  RHS range        [1e+04, 1e+04]\n",
      "Presolve removed 1 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds (0.00 work units)\n",
      "Optimal objective  1.000000000e+00\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m inputs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m3000\u001b[39m, \u001b[38;5;241m4000\u001b[39m,\u001b[38;5;241m5\u001b[39m]  \u001b[38;5;66;03m# initial guess\u001b[39;00m\n\u001b[1;32m     66\u001b[0m model_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/yui/Downloads/read_and_play/model_output\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Adjust the path as necessary\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 55\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(inputs, model_directory)\u001b[0m\n\u001b[1;32m     52\u001b[0m optimized_inputs \u001b[38;5;241m=\u001b[39m [x[i]\u001b[38;5;241m.\u001b[39mX \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))]\n\u001b[1;32m     54\u001b[0m predictor \u001b[38;5;241m=\u001b[39m QuantileModelPredictor(model_directory)\n\u001b[0;32m---> 55\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimized_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Set objective to maximize the weighted sum of predictions\u001b[39;00m\n\u001b[1;32m     58\u001b[0m weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mlen\u001b[39m(predictions))  \u001b[38;5;66;03m# Example weights increasing from 1 to 2\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 32\u001b[0m, in \u001b[0;36mQuantileModelPredictor.predict\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     30\u001b[0m output \u001b[38;5;241m=\u001b[39m inputs_scaled\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(weights, biases):\n\u001b[0;32m---> 32\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m     33\u001b[0m     output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmaximum(output, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# ReLU activation\u001b[39;00m\n\u001b[1;32m     34\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])  \u001b[38;5;66;03m# Assuming last layer's output is needed\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Concatenation operation is not implemented for NumPy arrays, use np.concatenate() instead. Please do not rely on this error; it may not be given on all Python implementations."
     ]
    }
   ],
   "source": [
    "!pip install gurobipy\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "class QuantileModelPredictor:\n",
    "    def __init__(self, model_directory):\n",
    "        self.scaler = joblib.load(os.path.join(model_directory, 'scaler.pkl'))\n",
    "        quantiles = np.load(os.path.join(model_directory, 'quantiles.npy'), allow_pickle=True)\n",
    "        quantiles = np.sort(quantiles)  # Ensure quantiles are sorted\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for q in quantiles:\n",
    "            model_path = os.path.join(model_directory, f'model_quantile_{q:.2f}.pth')\n",
    "            model_info = torch.load(model_path)\n",
    "            # Assuming model weights and biases are stored as numpy arrays directly in 'weights'\n",
    "            self.weights.append(model_info['weights'])\n",
    "            self.biases.append(model_info['state_dict'][list(model_info['state_dict'].keys())[-1]])\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs_scaled = self.scaler.transform(np.array([inputs]))\n",
    "        outputs = []\n",
    "\n",
    "        for weights, biases in zip(self.weights, self.biases):\n",
    "            output = inputs_scaled\n",
    "            for w, b in zip(weights, biases):\n",
    "                output = np.dot(output, w.T) + b\n",
    "                output = np.maximum(output, 0)  # ReLU activation\n",
    "            outputs.append(output.flatten()[-1])  # Assuming last layer's output is needed\n",
    "\n",
    "        return outputs\n",
    "\n",
    "def optimize(inputs, model_directory):\n",
    "    model = gp.Model(\"NN_Optimization\")\n",
    "    x = model.addVars(len(inputs), lb=0, ub=10000, name=\"Inputs\")\n",
    "    model.update()\n",
    "\n",
    "    # Define a dummy objective for optimization. Actual objective will be set post-optimization\n",
    "    model.setObjective(1, GRB.MAXIMIZE)\n",
    "\n",
    "    # Add constraint that sum of inputs should not exceed a certain value\n",
    "    model.addConstr(gp.quicksum(x[i] for i in range(len(inputs))) <= 10000, \"c0\")\n",
    "\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        optimized_inputs = [x[i].X for i in range(len(inputs))]\n",
    "\n",
    "        predictor = QuantileModelPredictor(model_directory)\n",
    "        predictions = predictor.predict(optimized_inputs)\n",
    "\n",
    "        # Set objective to maximize the weighted sum of predictions\n",
    "        weights = np.linspace(1, 2, len(predictions))  # Example weights increasing from 1 to 2\n",
    "        objective = sum(weights[i] * predictions[i] for i in range(len(predictions)))\n",
    "        print(\"Optimized inputs:\", optimized_inputs)\n",
    "        print(\"Objective value (weighted sum of predictions):\", objective)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "inputs = [1000, 2000, 3000, 4000,5]  # initial guess\n",
    "model_directory = '/home/yui/Downloads/read_and_play/model_output'  # Adjust the path as necessary\n",
    "optimize(inputs, model_directory)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
