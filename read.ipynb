{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qunatiles: [0.5 0.6 0.4 0.7 0.3 0.8 0.2 0.9 0.1]\n",
      "Manual Outputs: [2426901354.444373, 2480358491.406657, 2307159306.8403263, 2601671413.990361, 2210020239.564946, 2872144448.735074, 2178552543.5306993, 7136673349.902651, 2097353085.123003]\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Self\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "#import torch\n",
    "\n",
    "class QuantileModelPredictor:\n",
    "    def __init__(self, model_directory):\n",
    "        # Load the scaler and ensure it outputs float64\n",
    "        self.scaler = joblib.load(os.path.join(model_directory, 'scaler.pkl'))\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Load quantiles and their corresponding model weights and biases\n",
    "        quantiles = np.load(os.path.join(model_directory, 'quantiles.npy'), allow_pickle=True)\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "        for q in self.quantiles:\n",
    "            model_path = os.path.join(model_directory, f'model_quantile_{q:.2f}.pth')\n",
    "            model_info = torch.load(model_path)\n",
    "            # Initialize lists to hold weights and biases for the quantile model\n",
    "            model_weights = []\n",
    "            model_biases = []\n",
    "\n",
    "            # Extract weights and biases from model state dictionary and convert them to float64\n",
    "            for name, param in model_info['state_dict'].items():\n",
    "                if 'weight' in name:\n",
    "                    model_weights.append(param.detach().numpy().astype(np.float64))\n",
    "                elif 'bias' in name:\n",
    "                    model_biases.append(param.detach().numpy().astype(np.float64))\n",
    "\n",
    "            self.weights.append(model_weights)\n",
    "            self.biases.append(model_biases)\n",
    "\n",
    "\n",
    "    def predict_quantiles(self, inputs):\n",
    "      inputs = np.array(inputs, dtype=np.float64).reshape(1, -1)\n",
    "      scaled_inputs = self.scaler.transform(inputs).astype(np.float64)\n",
    "\n",
    "      manual_outputs = []\n",
    "      for i in range(len(self.quantiles)):\n",
    "          x = scaled_inputs\n",
    "          layers = len(self.weights[i])\n",
    "          for j in range(layers):\n",
    "              weights = self.weights[i][j]\n",
    "              biases = self.biases[i][j]\n",
    "              x = np.dot(x, weights.T) + biases\n",
    "              if j < layers - 1:  # Apply ReLU to all but the last layer\n",
    "                  x = np.maximum(0, x)\n",
    "          manual_outputs.append(x.flatten()[0])\n",
    "\n",
    "      return manual_outputs\n",
    "\n",
    "# Usage example:\n",
    "model_directory = '/home/yui/Downloads/read_and_play/model_output'  # Adjust the path as necessary\n",
    "predictor = QuantileModelPredictor(model_directory)\n",
    "inputs = [5000, 1000, 15000, 2000]  # Example inputs\n",
    "manual_outputs = predictor.predict_quantiles(inputs)\n",
    "print(\"qunatiles:\", predictor.quantiles)\n",
    "print(\"Manual Outputs:\", manual_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
