{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qunatiles: [0.5 0.6 0.4 0.7 0.3 0.8 0.2 0.9 0.1]\n",
      "Manual Outputs: [2426901354.444373, 2480358491.406657, 2307159306.8403263, 2601671413.990361, 2210020239.564946, 2872144448.735074, 2178552543.5306993, 7136673349.902651, 2097353085.123003]\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import Self\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "class QuantileModelPredictor:\n",
    "    def __init__(self, model_directory):\n",
    "        # Load the scaler and ensure it outputs float64\n",
    "        self.scaler = joblib.load(os.path.join(model_directory, 'scaler.pkl'))\n",
    "\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Load quantiles and their corresponding model weights and biases\n",
    "        quantiles = np.load(os.path.join(model_directory, 'quantiles.npy'), allow_pickle=True)\n",
    "        self.quantiles = quantiles\n",
    "\n",
    "        for q in self.quantiles:\n",
    "            model_path = os.path.join(model_directory, f'model_quantile_{q:.2f}.pth')\n",
    "            model_info = torch.load(model_path)\n",
    "            # Initialize lists to hold weights and biases for the quantile model\n",
    "            model_weights = []\n",
    "            model_biases = []\n",
    "\n",
    "            # Extract weights and biases from model state dictionary and convert them to float64\n",
    "            for name, param in model_info['state_dict'].items():\n",
    "                if 'weight' in name:\n",
    "                    model_weights.append(param.detach().numpy().astype(np.float64))\n",
    "                elif 'bias' in name:\n",
    "                    model_biases.append(param.detach().numpy().astype(np.float64))\n",
    "\n",
    "            self.weights.append(model_weights)\n",
    "            self.biases.append(model_biases)\n",
    "\n",
    "\n",
    "    def predict_quantiles(self, inputs):\n",
    "      inputs = np.array(inputs, dtype=np.float64).reshape(1, -1)\n",
    "      scaled_inputs = self.scaler.transform(inputs).astype(np.float64)\n",
    "\n",
    "      manual_outputs = []\n",
    "      for i in range(len(self.quantiles)):\n",
    "          x = scaled_inputs\n",
    "          layers = len(self.weights[i])\n",
    "          for j in range(layers):\n",
    "              weights = self.weights[i][j]\n",
    "              biases = self.biases[i][j]\n",
    "              x = np.dot(x, weights.T) + biases\n",
    "              if j < layers - 1:  # Apply ReLU to all but the last layer\n",
    "                  x = np.maximum(0, x)\n",
    "          manual_outputs.append(x.flatten()[0])\n",
    "\n",
    "      return manual_outputs\n",
    "\n",
    "# Usage example:\n",
    "model_directory = '/home/yui/Downloads/read_and_play/model_output'  # Adjust the path as necessary\n",
    "predictor = QuantileModelPredictor(model_directory)\n",
    "inputs = [5000, 1000, 15000, 2000,5]  # Example inputs\n",
    "manual_outputs = predictor.predict_quantiles(inputs)\n",
    "print(\"qunatiles:\", predictor.quantiles)\n",
    "print(\"Manual Outputs:\", manual_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gurobipy in /home/yui/.local/lib/python3.10/site-packages (11.0.2)\n",
      "Gurobi Optimizer version 11.0.2 build v11.0.2rc0 (linux64 - \"Ubuntu 22.04.4 LTS\")\n",
      "\n",
      "CPU model: 11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1 rows, 5 columns and 5 nonzeros\n",
      "Model fingerprint: 0x0f216fb8\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [1e+04, 1e+04]\n",
      "  RHS range        [1e+04, 1e+04]\n",
      "Presolve removed 1 rows and 5 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    1.0000000e+00   0.000000e+00   0.000000e+00      0s\n",
      "\n",
      "Solved in 0 iterations and 0.00 seconds (0.00 work units)\n",
      "Optimal objective  1.000000000e+00\n",
      "Optimized inputs: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Weighted sum of predictions: 21.349517563705625\n"
     ]
    }
   ],
   "source": [
    "!pip install gurobipy\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import os\n",
    "class QuantileModelPredictor:\n",
    "    def __init__(self, model_directory):\n",
    "        self.scaler = joblib.load(os.path.join(model_directory, 'scaler.pkl'))\n",
    "        quantiles = np.load(os.path.join(model_directory, 'quantiles.npy'), allow_pickle=True)\n",
    "        self.models = []\n",
    "\n",
    "        for q in sorted(quantiles):\n",
    "            model_path = os.path.join(model_directory, f'model_quantile_{q:.2f}.pth')\n",
    "            model_info = torch.load(model_path)\n",
    "            self.models.append((model_info['weights'], model_info['state_dict']['output_layer.bias'].numpy()))\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        inputs_scaled = self.scaler.transform(np.array([inputs]))\n",
    "        outputs = []\n",
    "\n",
    "        for weights, bias in self.models:\n",
    "            output = inputs_scaled\n",
    "            for w, b in zip(weights, bias):\n",
    "                output = np.dot(output, w.T) + b\n",
    "                output = np.maximum(output, 0)  # ReLU activation\n",
    "            outputs.append(output.flatten()[-1])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "def optimize(inputs, model_directory):\n",
    "    model = gp.Model(\"Quantile_Optimization\")\n",
    "    x_vars = model.addVars(len(inputs), lb=0, ub=10000, name=\"Inputs\")\n",
    "    model.update()\n",
    "\n",
    "    # Objective function placeholder\n",
    "    model.setObjective(1, GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    model.addConstr(gp.quicksum(x_vars[i] for i in range(len(inputs))) <= 10000, \"InputSumConstraint\")\n",
    "\n",
    "    # Optimize model to find best inputs\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        optimized_inputs = [x_vars[i].X for i in range(len(inputs))]\n",
    "\n",
    "        # Evaluate optimized inputs using the neural network model\n",
    "        predictor = QuantileModelPredictor(model_directory)\n",
    "        predictions = predictor.predict(optimized_inputs)\n",
    "\n",
    "        # Compute weighted sum of outputs as the true objective\n",
    "        weights = np.linspace(1, 2, len(predictions))  # Increasing weights as an example\n",
    "        weighted_sum = sum(w * p for w, p in zip(weights, predictions))\n",
    "\n",
    "        print(\"Optimized inputs:\", optimized_inputs)\n",
    "        print(\"Weighted sum of predictions:\", weighted_sum)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "inputs = [1000, 2000, 3000, 4000,5]  # initial guess\n",
    "model_directory = '/home/yui/Downloads/read_and_play/model_output'  # Adjust the path as necessary\n",
    "optimize(inputs, model_directory)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
